{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "from torch.utils.data.dataloader import DataLoader,Sampler\n",
    "import torchvision\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'label'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "data = datasets.load_dataset('fashion_mnist')\n",
    "train_data = data['train'].select(range(2000))\n",
    "print(train_data)\n",
    "comp = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    #torchvision.transforms.(),\n",
    "    \n",
    "\n",
    "])\n",
    "pos_comp = torchvision.transforms.Compose([\n",
    "    #torchvision.transforms.RandomVerticalFlip(),\n",
    "    #torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandAugment(),\n",
    "    torchvision.transforms.Lambda(lambda x: 2* x/255.0 -1  )\n",
    "])\n",
    "\n",
    "#train_data = train_data.map(lambda x :{'image': comp(x['image']) ,'label' :x['label']} ,batch_size=32)\n",
    "#positive_data = train_data.map(lambda x :{'image': comp(x['image']) ,'label':1} )\n",
    "#sampler = Sampler(train_data)\n",
    "batch_size = 100\n",
    "def custom_collate_fn(batch):\n",
    "    images = []\n",
    "    for x in batch:\n",
    "        img:torch.Tensor = comp(x['image']) \n",
    "        img = img.to(torch.uint8)\n",
    "        images.append(pos_comp(img))\n",
    "        aug = pos_comp(img)\n",
    "        images.append(aug)\n",
    "        \n",
    "    #images.append(aug)\n",
    "    \n",
    "    #rint = torch.randint(0,len(batch),(1,)).numpy()[0]\n",
    "    #images.append(pos_comp(images[rint]))\n",
    "    #labels = torch.zeros(size=(len(batch)+1,))\n",
    "    #labels[rint]=1\n",
    "    #labels[-1] =1 \n",
    "    # shaffel images and corresponding label ??\n",
    "    \n",
    "    # Convert the list of images to a tensor\n",
    "    images = torch.stack(images)\n",
    "\n",
    "    # Shuffle the images and their corresponding labels\n",
    "    #perm = torch.randperm(images.size(0))\n",
    "    #images = images[perm]\n",
    "    #labels = labels[perm]\n",
    "    \n",
    "    \n",
    "    return images.to(device)#, labels\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size//2 , collate_fn=custom_collate_fn) #,sampler=sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for d in train_loader:\n",
    "    print( d.shape) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt_xent_loss(x, temperature):\n",
    "  #assert len(x.size()) == 2\n",
    "\n",
    "  # Cosine similarity\n",
    "  xcs = torch.cosine_similarity(x[None,:,:], x[:,None,:], dim=-1)\n",
    "  xcs[torch.eye(x.size(0)).bool()] = float(\"-inf\")\n",
    "\n",
    "  # Ground truth labels\n",
    "  target = torch.arange(x.shape[0]).to(device)\n",
    "  target[0::2] += 1\n",
    "  target[1::2] -= 1\n",
    "\n",
    "  # Standard cross-entropy loss\n",
    "  return torch.nn.functional.cross_entropy(torch.exp( xcs / temperature), target, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]             640\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "              ReLU-3           [-1, 64, 28, 28]               0\n",
      "         MaxPool2d-4             [-1, 64, 9, 9]               0\n",
      "            Conv2d-5            [-1, 256, 9, 9]         147,712\n",
      "       BatchNorm2d-6            [-1, 256, 9, 9]             512\n",
      "              ReLU-7            [-1, 256, 9, 9]               0\n",
      "         MaxPool2d-8            [-1, 256, 3, 3]               0\n",
      "            Conv2d-9            [-1, 512, 1, 1]       1,180,160\n",
      "      BatchNorm2d-10            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-11            [-1, 512, 1, 1]               0\n",
      "          Flatten-12                  [-1, 512]               0\n",
      "          Dropout-13                  [-1, 512]               0\n",
      "================================================================\n",
      "Total params: 1,330,176\n",
      "Trainable params: 1,330,176\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.70\n",
      "Params size (MB): 5.07\n",
      "Estimated Total Size (MB): 6.78\n",
      "----------------------------------------------------------------\n",
      "0  : 2595.234\n",
      "10  : 2385.012\n",
      "20  : 2230.3271\n",
      "30  : 1736.3727\n",
      "40  : 2052.9795\n",
      "50  : 1723.8473\n",
      "60  : 2043.9911\n",
      "70  : 1693.4397\n",
      "80  : 1873.979\n",
      "90  : 1755.55\n"
     ]
    }
   ],
   "source": [
    "def kl(P):\n",
    "    #n = torch.distributions.Normal(torch.zeros(out.shape), torch.ones(out.shape))\n",
    "    #n = torch.Tensor(n)\n",
    "    #Q = torch.normal(0,1,size=P.shape).to(device)\n",
    "    #return torch.distributions.kl_divergence(out,n)\n",
    "    \n",
    "    #return (P * (P / Q).log()).sum()\n",
    "    pass\n",
    "\n",
    "import torchsummary\n",
    "model = torch.nn.Sequential(\n",
    " nn.Conv2d(1, 64, (3, 3), 1, 1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3),\n",
    "\n",
    "    nn.Conv2d(64, 256, (3, 3), 1, 1),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(3),\n",
    "\n",
    "    nn.Conv2d(256, 512, (3, 3), 1),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ReLU(),\n",
    "    nn.Flatten(),\n",
    "    nn.Dropout(0.5),\n",
    "    \n",
    "    #torch.nn.Linear(512,128),\n",
    "    #torch.nn.Tanh()\n",
    "    \n",
    ")\n",
    "model = model.to(device)\n",
    "torchsummary.summary(model,(1,28,28),device=device)\n",
    "cross_entropy = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optim = torch.optim.RAdam(model.parameters(),lr=1e-4)\n",
    "def step(x):\n",
    "    optim.zero_grad()\n",
    "    out = model.forward(x)\n",
    "    #print(out.shape)\n",
    "    t = 0.07\n",
    "    #z_img = out[0::2]\n",
    "    #z_aug = out[1::2]\n",
    "    \n",
    "\n",
    "    loss = nt_xent_loss(out,t) #+ kl(out) #0.01* torch.sum(out)**2\n",
    "    \n",
    "\n",
    "\n",
    "    loss.backward()  \n",
    "    \n",
    "    optim.step()\n",
    "    return loss\n",
    "    pass\n",
    "for epochs in range(100):\n",
    "    for image in train_loader:\n",
    "        loss = step(image)\n",
    "        \n",
    "    if epochs%10==0:\n",
    "        print(epochs,' :', loss.detach().cpu().numpy())\n",
    "        pass\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
       " \n",
       " \n",
       "         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
       " \n",
       " \n",
       "         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
       " \n",
       " \n",
       "         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -0.9941, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -0.9976, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
       " \n",
       " \n",
       "         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]],\n",
       "        device='cuda:0'),\n",
       " tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
       "         1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7, 6, 7, 2, 1,\n",
       "         2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1, 2, 3, 9, 8, 7, 0,\n",
       "         2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2, 0, 6, 5, 3, 6, 7, 1, 8,\n",
       "         0, 1, 4, 2], device='cuda:0'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = data['test'].select(range(1000))\n",
    "test_comp = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Lambda(lambda x: 2*x/255.0-1)\n",
    "])\n",
    "def test_collate_fn(batch):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for b in batch:\n",
    "        images.append(test_comp(b['image']))\n",
    "        labels.append(b['label'])\n",
    "        \n",
    "    images = torch.stack(images).to(device)   \n",
    "    labels = torch.Tensor(labels).type(torch.LongTensor).to(device)\n",
    "    return images,labels\n",
    "    pass \n",
    "test_loader = DataLoader(test_data,batch_size,False,collate_fn=test_collate_fn)\n",
    "\n",
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0467, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6798, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2741, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "    \n",
    "new_model = torch.nn.Sequential(\n",
    "    model,\n",
    "    torch.nn.Linear(512,10),\n",
    "    #torch.nn.Softmax(),\n",
    ")\n",
    "\n",
    "new_model= new_model.to(device)\n",
    "\n",
    "new_optim = torch.optim.RAdam(new_model.parameters(),1e-3)\n",
    "lossfnc= torch.nn.CrossEntropyLoss()\n",
    "def new_step(x,y):\n",
    "    new_optim.zero_grad()\n",
    "    out = new_model.forward(x)\n",
    "    loss = lossfnc.forward(out,y)\n",
    "    loss.backward()\n",
    "    new_optim.step()    \n",
    "    return loss\n",
    "    pass\n",
    "\n",
    "\n",
    "for epochs in range(20):\n",
    "    for x,y in test_loader:\n",
    "        loss = new_step(x,y)\n",
    "        pass\n",
    "    print(loss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor(2.3311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(2.3448, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(2.1906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(2.1696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(2.0499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(2.0258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.8667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.7390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.6636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.6122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.5382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.5184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.3928, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.3227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.3132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.2306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.1824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.1322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.1127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
    "tensor(1.0835, device='cuda:0', grad_fn=<NllLossBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "tensor(0.8200, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "m= new_model.eval() \n",
    "\n",
    "for x,y in test_loader:\n",
    "   out = m.forward(x) \n",
    "   r = torch.argmax(out,dim=1)\n",
    "   print(r.shape)\n",
    "   print((r==y).int().sum()/out.shape[0])\n",
    "   \n",
    "   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    for i in range(0,for_range):\n",
    "        n = torch.exp(torch.cosine_similarity(z_img[i:i+1], z_aug[i:i+1] )/t)\n",
    "        \n",
    "        d= torch.Tensor([0.0]).to(device)\n",
    "        \n",
    "        for j in range(0,for_range):\n",
    "            \n",
    "            if i!=j:\n",
    "                d += torch.exp(torch.cosine_similarity(z_img[i:i+1],z_img[j:j+1]))\n",
    "                pass\n",
    "        \n",
    "        loss += torch.log(n/d)\n",
    "        \n",
    "        \n",
    "        \n",
    "    loss /=- for_range  \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
